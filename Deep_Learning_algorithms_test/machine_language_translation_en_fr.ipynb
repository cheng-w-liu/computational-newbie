{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mock notebook motivated by an awesome blogpost: https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    path_to_input = os.path.join(path)\n",
    "    with open(path_to_input, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_english_input = 'MLT/data/small_vocab_en'\n",
    "path_to_french_output = 'MLT/data/small_vocab_fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "\n",
    "START_OF_SENTENCE_FLAG = '<GO>'\n",
    "END_OF_SENTENCE_FLAG = '<EOS>'\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    params: \n",
    "    text: raw text without being splitted \n",
    "    \"\"\"\n",
    "    vocab = set(text.split())\n",
    "    \n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "    \n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "        \n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    source_text: unsplit raw string from source\n",
    "    target_text: unplit raw string from target\n",
    "    source_vocab_to_int: dictionary that maps each word in the source_text to an integer\n",
    "    target_vocab_to_int: dictionary that maps each word in the target_text to an integer\n",
    "    \"\"\"\n",
    "    \n",
    "    # each will be a list of lists\n",
    "    source_text_id = []\n",
    "    target_text_id = []\n",
    "    \n",
    "    source_sentences = source_text.split('\\n')\n",
    "    target_sentences = target_text.split('\\n')\n",
    "    \n",
    "    assert len(source_sentences) == len(target_sentences)\n",
    "    \n",
    "    for i in range(len(source_sentences)):\n",
    "        \n",
    "        source_sentence = source_sentences[i]\n",
    "        target_sentence = target_sentences[i]\n",
    "        \n",
    "        source_tokens = source_sentence.split(' ')\n",
    "        target_tokens = target_sentence.split(' ')\n",
    "        \n",
    "        source_token_id = []\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if token != \"\":\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "                \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if token != \"\":\n",
    "                target_token_id.append(target_vocab_to_int[token])                \n",
    "        # IMPORTANT! Add a EOS flag at the end of each target sentence\n",
    "        target_token_id.append(target_vocab_to_int[END_OF_SENTENCE_FLAG])\n",
    "        \n",
    "        source_text_id.append(source_token_id)    \n",
    "        target_text_id.append(target_token_id)\n",
    "    \n",
    "    return source_text_id, target_text_id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(source_path, target_path, text_to_ids_func):\n",
    "    source_text = load_data(source_path).lower()\n",
    "    target_text = load_data(target_path).lower()\n",
    "    \n",
    "    source_vocab_to_int, source_int_to_vocab = create_lookup_tables(source_text)\n",
    "    target_vocab_to_int, target_int_to_vocab = create_lookup_tables(target_text)\n",
    "    \n",
    "    source_text_id, target_text_id = text_to_ids_func(source_text, target_text, source_vocab_to_int, target_vocab_to_int)\n",
    "    \n",
    "    pickle.dump(\n",
    "        ((source_text_id, target_text_id),\n",
    "         (source_vocab_to_int, target_vocab_to_int),\n",
    "         (source_int_to_vocab, target_int_to_vocab)),\n",
    "        open('MLT/preprocess.p', 'wb')\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_preprocess():\n",
    "    with open('MLT/preprocess.p', mode='rb') as fh:\n",
    "        return pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(path_to_english_input, path_to_french_output, text_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(source_text_int, target_text_int), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.1'), 'Please use TensorFlow version 1.1 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_decoder_model_inputs():\n",
    "    \"\"\"\n",
    "    return:\n",
    "    inputs: placeholder for the input, size [batch_size, max_sequence_length]\n",
    "    targets: placeholder for the output, size [batch_size, max_sequence_length]\n",
    "    \"\"\"\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')  # (batch_size, legnths of sentences)\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)\n",
    "    \n",
    "    return inputs, targets, target_sequence_length, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperparam_inputs():\n",
    "    \"\"\"\n",
    "    return (learning_rate, dropout_probability)\n",
    "    \"\"\"\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return learning_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    target_data with each training example being prefixed with the id of the '<GO>' tag \n",
    "    \"\"\"\n",
    "    start_id = target_vocab_to_int['<GO>']\n",
    "    prefixed_target_data = tf.concat([tf.fill([batch_size, 1], start_id), \n",
    "                                    target_data], \n",
    "                                   1)\n",
    "    return prefixed_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_encoder(rnn_inputs, rnn_size, num_layers, keep_prob,\n",
    "                  source_vocab_size, encoder_embedding_size):\n",
    "    \"\"\"\n",
    "    params:\n",
    "      rnn_inputs: input tensor, size: [batch_size, sequence_length]\n",
    "      rnn_size: size of the RNN\n",
    "      num_layers: numb. of the RNN layers to be stacked \n",
    "      keep_prob: drop out probability\n",
    "      source_vocab_size: vocabulary size of the source text\n",
    "      encoder_embedding_size: embedding size for encoder's embedding dimension\n",
    "    return:\n",
    "      outputs: outputs from the, shape: [batch_size, sequence_length, output_dimension]\n",
    "      state: emboder's state, shape: ???\n",
    "    \"\"\"\n",
    "    \n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, \n",
    "                                             vocab_size=source_vocab_size,\n",
    "                                             embed_dim=encoder_embedding_size)\n",
    "    # embed has shape: [batch_size, sequence_length, embed_dim]\n",
    "    \n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])    \n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=stacked_cells, \n",
    "                                       inputs=embed,\n",
    "                                       dtype=tf.float32)\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_decoder_for_training(encoder_state, decoder_cell, decoder_embedding_inputs,\n",
    "                               target_sequence_length, max_target_sequence_length, \n",
    "                               output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    params:\n",
    "      encoder_state: output states from the encoder part \n",
    "      decoder_cell: RNN cell(s) for the decoder\n",
    "      decoder_embedding_inputs: embedding inputs for the decoder\n",
    "      target_sequence_length: An int32 vector tensor, to be passed to TrainingHelper\n",
    "      max_target_sequence_length: maximum allowed number of decoding step\n",
    "      output_layer:\n",
    "      keep_prob: \n",
    "    returns:\n",
    "      outputs: outputs of the decoder for the training phase, shape: ???\n",
    "    \"\"\"\n",
    "    \n",
    "    decoder_cell = tf.contrib.rnn.DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(inputs=decoder_embedding_inputs, \n",
    "                                               sequence_length=target_sequence_length)\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                              helper=helper,\n",
    "                                              initial_state=encoder_state,\n",
    "                                              output_layer=output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True,\n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_decoder_for_inference(encoder_state, decoder_cell, decoder_embeddings,\n",
    "                                start_of_sequence_id, end_of_sequence_id,\n",
    "                                max_target_sequence_length, \n",
    "                                output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    params:\n",
    "      encoder_state: output states from the encoder\n",
    "      decoder_cell: RNN cell(s) for the decoder\n",
    "      decoder_embeddings: embeddings for the decoder\n",
    "      start_of_sequence_id: the id corresponding to the START_OF_SEQUENCE flag\n",
    "      end_of_sequence_id: the id corresponding to the END_OF_SEQUENCE flag\n",
    "      max_target_sequence_length: the max of the target_sequence_lengths\n",
    "      output_layer: output layer \n",
    "      batch_size: \n",
    "      keep_prob:\n",
    "    returns:\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    decoder_cell = tf.contrib.rnn.DropoutWrapper(decoder_cell, output_keep_prob=keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding=decoder_embeddings,\n",
    "                                                      start_tokens=tf.fill([batch_size], start_of_sequence_id),\n",
    "                                                      end_token=end_of_sequence_id)                                   \n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(cell=decoder_cell,\n",
    "                                              helper=helper,\n",
    "                                              initial_state=encoder_state,\n",
    "                                              output_layer=output_layer)\n",
    "    \n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n",
    "                                                      impute_finished=True,\n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_decoder(decoder_input, encoder_state,\n",
    "                  target_sequence_length, max_target_sequence_length,\n",
    "                  rnn_size, num_layers, \n",
    "                  target_vocab_to_int,\n",
    "                  batch_size, keep_prob, decoder_embedding_size):\n",
    "    \"\"\"\n",
    "    params:\n",
    "      decoder_input: sequence of integers, shape: [batch_size, sequence_length]\n",
    "      encoder_state: encoder output state\n",
    "      target_sequence_length: An int32 vector tensor, to be passed to TrainingHelper\n",
    "      max_target_sequence_length: maximum target sequence length\n",
    "      rnn_size: size of the RNN\n",
    "      num_layers: numb. of the RNN layers to be stacked \n",
    "      target_vocab_to_int: mappings from a target word to int\n",
    "      batch_size: batch_size\n",
    "      keep_prob: drop out probability\n",
    "      decoder_embedding_size: embedding size for decoder's embedding dimension\n",
    "    returns:\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    decoder_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoder_embedding_size]))\n",
    "    decoder_embedding_input = tf.nn.embedding_lookup(decoder_embeddings, decoder_input)\n",
    "        \n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        #output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        output_layer = Dense(target_vocab_size)\n",
    "        decoder_training_output = build_decoder_for_training(encoder_state, \n",
    "                                                             stacked_cells,\n",
    "                                                             decoder_embedding_input,\n",
    "                                                             target_sequence_length,\n",
    "                                                             max_target_sequence_length,\n",
    "                                                             output_layer,\n",
    "                                                             keep_prob)\n",
    "        \n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        decoder_inference_output = build_decoder_for_inference(encoder_state,\n",
    "                                                               stacked_cells,\n",
    "                                                               decoder_embeddings,\n",
    "                                                               target_vocab_to_int[START_OF_SENTENCE_FLAG],\n",
    "                                                               target_vocab_to_int[END_OF_SENTENCE_FLAG],\n",
    "                                                               max_target_sequence_length,\n",
    "                                                               output_layer,\n",
    "                                                               batch_size,\n",
    "                                                               keep_prob)\n",
    "\n",
    "    return (decoder_training_output, decoder_inference_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length, max_target_sequence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  encoder_embedding_size, decoder_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_output, encoder_state = build_encoder(input_data, rnn_size, num_layers, keep_prob,\n",
    "                                                  source_vocab_size, encoder_embedding_size)\n",
    "    \n",
    "    decoder_input = process_decoder_input(target_data, target_vocab_to_int, batch_size)\n",
    "    \n",
    "    training_output, inference_output = build_decoder(decoder_input, encoder_state,\n",
    "                                                      target_sequence_length, max_target_sequence_length,\n",
    "                                                      rnn_size, num_layers, \n",
    "                                                      target_vocab_to_int,\n",
    "                                                      batch_size, keep_prob, decoder_embedding_size)\n",
    "    \n",
    "    return training_output, inference_output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_step = 200\n",
    "\n",
    "epochs = 6\n",
    "batch_size = 128\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 3\n",
    "\n",
    "encoder_embedding_size = 200\n",
    "decoder_embedding_size = 200\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'MLT/checkpoints/dev'\n",
    "\n",
    "(source_text_int, target_text_int), (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, target_data, target_sequence_length, max_target_sequence_length = encoder_decoder_model_inputs()\n",
    "    \n",
    "    param_learning_rate, param_keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(input_data,\n",
    "                                                   target_data,\n",
    "                                                   param_keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoder_embedding_size,\n",
    "                                                   decoder_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "                                                   \n",
    "    train_logits_output = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    train_prediction = tf.identity(inference_logits.sample_id, name='prediction')\n",
    "    \n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length,\n",
    "                             dtype=tf.float32, name='masks')\n",
    "    \n",
    "    with tf.name_scope('optimization'):\n",
    "        \n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits=train_logits_output,\n",
    "            targets=target_data,\n",
    "            weights=masks)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(param_learning_rate)\n",
    "        \n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        clipped_gradients = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in gradients if grad is not None]\n",
    "        \n",
    "        train_op = optimizer.apply_gradients(clipped_gradients)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    for batch_idx in range(len(sources) // batch_size):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        sources_batch = sources[start_idx: end_idx]\n",
    "        targets_batch = targets[start_idx: end_idx]\n",
    "        \n",
    "        padded_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        padded_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "        \n",
    "        padded_sources_lengths = []\n",
    "        for source in padded_sources_batch:\n",
    "            padded_sources_lengths.append(len(source))\n",
    "            \n",
    "        padded_targets_lengths = []\n",
    "        for target in padded_targets_batch:\n",
    "            padded_targets_lengths.append(len(target))\n",
    "            \n",
    "        yield padded_sources_batch, padded_targets_batch, padded_sources_lengths, padded_targets_lengths       \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(targets, predictions, padding_int=0):\n",
    "    max_sequence_length = max(targets.shape[1], predictions.shape[1])\n",
    "    \n",
    "    if max_sequence_length > targets.shape[1]:\n",
    "        targets = np.pad(targets, \n",
    "                         [(0, 0), (0, max_sequence_length - targets.shape[1])],\n",
    "                         mode='constant',\n",
    "                         constant_values=padding_int)\n",
    "        \n",
    "    if max_sequence_length > predictions.shape[1]:\n",
    "        predictions = np.pad(predictions,\n",
    "                             [(0, 0), (0, max_sequence_length - predictions.shape[1])],\n",
    "                             mode='constant',\n",
    "                             constant_values=padding_int)\n",
    "        \n",
    "    return np.mean(np.equal(targets, predictions))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sources = source_text_int[batch_size:]\n",
    "train_targets = target_text_int[batch_size:]\n",
    "valid_sources = source_text_int[:batch_size]\n",
    "valid_targets = target_text_int[:batch_size]\n",
    "\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths) = \\\n",
    "  next(get_batches(valid_sources, \n",
    "                   valid_targets, \n",
    "                   batch_size, \n",
    "                   source_vocab_to_int['<PAD>'],\n",
    "                   target_vocab_to_int['<PAD>']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  200/1077 - Train Accuracy: 0.4570, Validation Accuracy: 0.5149, Loss: 2.2556\n",
      "Epoch   0 Batch  400/1077 - Train Accuracy: 0.4629, Validation Accuracy: 0.5014, Loss: 1.5660\n",
      "Epoch   0 Batch  600/1077 - Train Accuracy: 0.5212, Validation Accuracy: 0.5515, Loss: 1.1406\n",
      "Epoch   0 Batch  800/1077 - Train Accuracy: 0.4867, Validation Accuracy: 0.5685, Loss: 0.9940\n",
      "Epoch   0 Batch 1000/1077 - Train Accuracy: 0.5874, Validation Accuracy: 0.5700, Loss: 0.8334\n",
      "Epoch   1 Batch  200/1077 - Train Accuracy: 0.5395, Validation Accuracy: 0.5994, Loss: 0.7999\n",
      "Epoch   1 Batch  400/1077 - Train Accuracy: 0.5805, Validation Accuracy: 0.6005, Loss: 0.7432\n",
      "Epoch   1 Batch  600/1077 - Train Accuracy: 0.6183, Validation Accuracy: 0.6335, Loss: 0.6269\n",
      "Epoch   1 Batch  800/1077 - Train Accuracy: 0.5695, Validation Accuracy: 0.6417, Loss: 0.6264\n",
      "Epoch   1 Batch 1000/1077 - Train Accuracy: 0.6414, Validation Accuracy: 0.6445, Loss: 0.5331\n",
      "Epoch   2 Batch  200/1077 - Train Accuracy: 0.5813, Validation Accuracy: 0.6470, Loss: 0.5485\n",
      "Epoch   2 Batch  400/1077 - Train Accuracy: 0.6324, Validation Accuracy: 0.6687, Loss: 0.5210\n",
      "Epoch   2 Batch  600/1077 - Train Accuracy: 0.6667, Validation Accuracy: 0.6687, Loss: 0.4569\n",
      "Epoch   2 Batch  800/1077 - Train Accuracy: 0.6527, Validation Accuracy: 0.6740, Loss: 0.4590\n",
      "Epoch   2 Batch 1000/1077 - Train Accuracy: 0.7191, Validation Accuracy: 0.6914, Loss: 0.4170\n",
      "Epoch   3 Batch  200/1077 - Train Accuracy: 0.6727, Validation Accuracy: 0.7017, Loss: 0.4171\n",
      "Epoch   3 Batch  400/1077 - Train Accuracy: 0.7148, Validation Accuracy: 0.7013, Loss: 0.4178\n",
      "Epoch   3 Batch  600/1077 - Train Accuracy: 0.7277, Validation Accuracy: 0.7163, Loss: 0.3674\n",
      "Epoch   3 Batch  800/1077 - Train Accuracy: 0.6852, Validation Accuracy: 0.7287, Loss: 0.3735\n",
      "Epoch   3 Batch 1000/1077 - Train Accuracy: 0.7526, Validation Accuracy: 0.7372, Loss: 0.3326\n",
      "Epoch   4 Batch  200/1077 - Train Accuracy: 0.7137, Validation Accuracy: 0.7319, Loss: 0.3344\n",
      "Epoch   4 Batch  400/1077 - Train Accuracy: 0.7613, Validation Accuracy: 0.7482, Loss: 0.3254\n",
      "Epoch   4 Batch  600/1077 - Train Accuracy: 0.7571, Validation Accuracy: 0.7422, Loss: 0.2780\n",
      "Epoch   4 Batch  800/1077 - Train Accuracy: 0.6941, Validation Accuracy: 0.7390, Loss: 0.2793\n",
      "Epoch   4 Batch 1000/1077 - Train Accuracy: 0.7790, Validation Accuracy: 0.7418, Loss: 0.2371\n",
      "Epoch   5 Batch  200/1077 - Train Accuracy: 0.7484, Validation Accuracy: 0.7596, Loss: 0.2509\n",
      "Epoch   5 Batch  400/1077 - Train Accuracy: 0.7969, Validation Accuracy: 0.7699, Loss: 0.2396\n",
      "Epoch   5 Batch  600/1077 - Train Accuracy: 0.8471, Validation Accuracy: 0.8072, Loss: 0.1961\n",
      "Epoch   5 Batch  800/1077 - Train Accuracy: 0.8426, Validation Accuracy: 0.8452, Loss: 0.1946\n",
      "Epoch   5 Batch 1000/1077 - Train Accuracy: 0.8620, Validation Accuracy: 0.8249, Loss: 0.1657\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch_idx in range(epochs):\n",
    "        for batch_idx, (sources_batch, targets_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "          get_batches(train_sources,\n",
    "                      train_targets,\n",
    "                      batch_size,\n",
    "                      source_vocab_to_int['<PAD>'],\n",
    "                      target_vocab_to_int['<PAD>']\n",
    "                      )):\n",
    "        \n",
    "            _, loss = sess.run([train_op, cost], \n",
    "                               feed_dict={\n",
    "                                   input_data: sources_batch,\n",
    "                                   target_data: targets_batch,\n",
    "                                   target_sequence_length: targets_lengths,\n",
    "                                   param_learning_rate: learning_rate, \n",
    "                                   param_keep_prob: keep_prob                               \n",
    "                               })\n",
    "        \n",
    "            if batch_idx % display_step == 0 and batch_idx > 0:\n",
    "                batch_train_predictions = sess.run(train_prediction, \n",
    "                                                   feed_dict={\n",
    "                                                       input_data: sources_batch,\n",
    "                                                       target_sequence_length: targets_lengths,\n",
    "                                                       param_keep_prob: 1.0\n",
    "                                                   })\n",
    "                \n",
    "                batch_valid_predictions = sess.run(train_prediction,\n",
    "                                                   feed_dict={\n",
    "                                                       input_data: valid_sources_batch,\n",
    "                                                       target_sequence_length: valid_targets_lengths,\n",
    "                                                       param_keep_prob: 1.0\n",
    "                                                   })\n",
    "                \n",
    "                train_acc = get_accuracy(targets_batch, batch_train_predictions)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_predictions)\n",
    "                \n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_idx, batch_idx, len(source_text_int) // batch_size, train_acc, valid_acc, loss))\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_params(save_path):\n",
    "    with open('MLT/params.p', 'wb') as fh:\n",
    "        pickle.dump(save_path, fh)\n",
    "        \n",
    "def load_params():\n",
    "    with open('MLT/params.p', 'rb') as fh:\n",
    "        return pickle.load(fh)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setence_to_seq(sentence, vocab_to_int):\n",
    "    seq = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            seq.append(vocab_to_int[word])\n",
    "        else:\n",
    "            seq.append(vocab_to_int['<UNK>'])\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_sentence = 'he saw a old yellow truck .'\n",
    "english_seq = setence_to_seq(english_sentence, source_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MLT/checkpoints/dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from MLT/checkpoints/dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "  Word Ids:      [115, 184, 51, 17, 107, 205, 23]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [227, 6, 31, 102, 175, 20, 193, 1]\n",
      "  French Words: il conduisait un gros camion jaune . <EOS>\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "    \n",
    "    input_data = loaded_graph.get_tensor_by_name('inputs:0')  # from encoder_decoder_model_inputs\n",
    "    predictions = loaded_graph.get_tensor_by_name('prediction:0') # from the main program that specifies the graph\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    param_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0') # from hyperparam_inputs\n",
    "    \n",
    "    french_seq = sess.run(predictions,\n",
    "                          feed_dict={\n",
    "                              input_data: [english_seq] * batch_size,\n",
    "                              target_sequence_length: [len(english_seq) * 2] * batch_size,\n",
    "                              param_keep_prob: 1.0                              \n",
    "                          })[0]\n",
    "                         \n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in english_seq]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in english_seq]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in french_seq]))\n",
    "print('  French Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in french_seq])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
